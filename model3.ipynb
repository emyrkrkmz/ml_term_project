{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32839c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season(df):\n",
    "    df = df.copy()\n",
    "    df[\"sin_week\"] = np.sin(2*np.pi*df[\"weekofyear\"]/52)\n",
    "    df[\"cos_week\"] = np.cos(2*np.pi*df[\"weekofyear\"]/52)\n",
    "    return df\n",
    "\n",
    "def interpolate_citywise(df):\n",
    "\n",
    "    df = df.sort_values([\"city\",\"year\",\"weekofyear\"]).copy()\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    for city in df[\"city\"].unique():\n",
    "        idx = df[\"city\"] == city\n",
    "        df.loc[idx, num_cols] = (\n",
    "            df.loc[idx, num_cols]\n",
    "              .interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def time_split(city_df, val_frac=0.2):\n",
    "    city_df = city_df.sort_values([\"year\",\"weekofyear\"]).copy()\n",
    "    n = len(city_df)\n",
    "    cut = int((1 - val_frac) * n)\n",
    "    return city_df.iloc[:cut], city_df.iloc[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc42337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_df(features_train_path=\"dengue_features_train.csv\",\n",
    "                  labels_train_path=\"dengue_labels_train.csv\"):\n",
    "    Xtr = pd.read_csv(features_train_path)\n",
    "    ytr = pd.read_csv(labels_train_path)\n",
    "\n",
    "    # seasonality\n",
    "    Xtr = add_season(Xtr)\n",
    "\n",
    "    # interpolate numeric inside each city\n",
    "    Xtr = interpolate_citywise(Xtr)\n",
    "\n",
    "    # merge labels\n",
    "    df = Xtr.merge(ytr, on=[\"city\",\"year\",\"weekofyear\"]).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # ---- Target lags (1-4)\n",
    "    for l in [1,2,3,4]:\n",
    "        df[f\"total_cases_lag_{l}\"] = df.groupby(\"city\")[\"total_cases\"].shift(l)\n",
    "\n",
    "    # ---- Target rolling (4) using shift(1) to avoid leakage\n",
    "    df[\"total_cases_roll_mean_4\"] = (\n",
    "        df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"total_cases_roll_std_4\"] = (\n",
    "        df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).std()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # ---- Env lag (1)\n",
    "    df[\"reanalysis_avg_temp_k_lag_1\"] = df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].shift(1)\n",
    "    df[\"precipitation_amt_mm_lag_1\"]  = df.groupby(\"city\")[\"precipitation_amt_mm\"].shift(1)\n",
    "\n",
    "    # ---- Env rolling (4)\n",
    "    df[\"temp_roll_mean_4\"] = (\n",
    "        df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].rolling(4, min_periods=1).mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"precip_roll_sum_4\"] = (\n",
    "        df.groupby(\"city\")[\"precipitation_amt_mm\"].rolling(4, min_periods=1).sum()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # ---- Env rolling (53)\n",
    "    df[\"temp_roll_mean_53\"] = (\n",
    "        df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].rolling(53, min_periods=1).mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"precip_roll_sum_53\"] = (\n",
    "        df.groupby(\"city\")[\"precipitation_amt_mm\"].rolling(53, min_periods=1).sum()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"humidity_roll_mean_53\"] = (\n",
    "        df.groupby(\"city\")[\"reanalysis_relative_humidity_percent\"].rolling(53, min_periods=1).mean()\n",
    "          .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0eb9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_df(features_train_path=\"dengue_features_train.csv\",\n",
    "                 features_test_path=\"dengue_features_test.csv\"):\n",
    "    Xtr = pd.read_csv(features_train_path)\n",
    "    Xte = pd.read_csv(features_test_path)\n",
    "\n",
    "    # seasonality\n",
    "    Xtr = add_season(Xtr)\n",
    "    Xte = add_season(Xte)\n",
    "\n",
    "    # interpolate\n",
    "    Xtr = interpolate_citywise(Xtr)\n",
    "    Xte = interpolate_citywise(Xte)\n",
    "\n",
    "    # We'll add env rolling features to Xte with seeding from Xtr.\n",
    "    Xte = Xte.sort_values([\"city\",\"year\",\"weekofyear\"]).copy()\n",
    "\n",
    "    out_parts = []\n",
    "    for city in [\"sj\", \"iq\"]:\n",
    "        trc = Xtr[Xtr[\"city\"] == city].sort_values([\"year\",\"weekofyear\"]).copy()\n",
    "        tec = Xte[Xte[\"city\"] == city].sort_values([\"year\",\"weekofyear\"]).copy()\n",
    "\n",
    "        # --- rolling 4: need last 3\n",
    "        seed4 = trc.tail(3)[[\"reanalysis_avg_temp_k\", \"precipitation_amt_mm\"]].copy()\n",
    "        combo4 = pd.concat([\n",
    "            seed4,\n",
    "            tec[[\"reanalysis_avg_temp_k\", \"precipitation_amt_mm\"]]\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        r4_temp = combo4[\"reanalysis_avg_temp_k\"].rolling(4, min_periods=1).mean()\n",
    "        r4_prec = combo4[\"precipitation_amt_mm\"].rolling(4, min_periods=1).sum()\n",
    "\n",
    "        r4_temp = r4_temp.iloc[len(seed4):].reset_index(drop=True)\n",
    "        r4_prec = r4_prec.iloc[len(seed4):].reset_index(drop=True)\n",
    "\n",
    "        # --- rolling 53: need last 52\n",
    "        seed53 = trc.tail(52)[[\"reanalysis_avg_temp_k\", \"precipitation_amt_mm\", \"reanalysis_relative_humidity_percent\"]].copy()\n",
    "        combo53 = pd.concat([\n",
    "            seed53,\n",
    "            tec[[\"reanalysis_avg_temp_k\", \"precipitation_amt_mm\", \"reanalysis_relative_humidity_percent\"]]\n",
    "        ], ignore_index=True)\n",
    "\n",
    "        r53_temp = combo53[\"reanalysis_avg_temp_k\"].rolling(53, min_periods=1).mean()\n",
    "        r53_prec = combo53[\"precipitation_amt_mm\"].rolling(53, min_periods=1).sum()\n",
    "        r53_hum  = combo53[\"reanalysis_relative_humidity_percent\"].rolling(53, min_periods=1).mean()\n",
    "\n",
    "        r53_temp = r53_temp.iloc[len(seed53):].reset_index(drop=True)\n",
    "        r53_prec = r53_prec.iloc[len(seed53):].reset_index(drop=True)\n",
    "        r53_hum  = r53_hum.iloc[len(seed53):].reset_index(drop=True)\n",
    "\n",
    "        tec = tec.reset_index(drop=True)\n",
    "        tec[\"temp_roll_mean_4\"] = r4_temp.values\n",
    "        tec[\"precip_roll_sum_4\"] = r4_prec.values\n",
    "\n",
    "        tec[\"temp_roll_mean_53\"] = r53_temp.values\n",
    "        tec[\"precip_roll_sum_53\"] = r53_prec.values\n",
    "        tec[\"humidity_roll_mean_53\"] = r53_hum.values\n",
    "\n",
    "        out_parts.append(tec)\n",
    "\n",
    "    Xte2 = pd.concat(out_parts, ignore_index=True).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "    return Xtr, Xte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1724dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb():\n",
    "    from xgboost import XGBRegressor\n",
    "    return XGBRegressor(\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        min_child_weight=3,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac066ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = [\n",
    "    \"year\", \"sin_week\", \"cos_week\",\n",
    "    \"ndvi_ne\",\"ndvi_nw\",\"ndvi_se\",\"ndvi_sw\",\n",
    "    \"precipitation_amt_mm\",\"reanalysis_precip_amt_kg_per_m2\",\n",
    "    \"reanalysis_sat_precip_amt_mm\",\"station_precip_mm\",\n",
    "    \"reanalysis_air_temp_k\",\"reanalysis_avg_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\"reanalysis_max_air_temp_k\",\n",
    "    \"station_avg_temp_c\",\"station_min_temp_c\",\"station_max_temp_c\",\n",
    "    \"reanalysis_relative_humidity_percent\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_tdtr_k\",\"station_diur_temp_rng_c\",\n",
    "]\n",
    "\n",
    "TARGET_LAG_ROLL = [\n",
    "    \"total_cases_lag_1\",\"total_cases_lag_2\",\"total_cases_lag_3\",\"total_cases_lag_4\",\n",
    "    \"total_cases_roll_mean_4\",\"total_cases_roll_std_4\",\n",
    "]\n",
    "\n",
    "ENV_LAG = [\n",
    "    \"reanalysis_avg_temp_k_lag_1\",\"precipitation_amt_mm_lag_1\",\n",
    "]\n",
    "\n",
    "ENV_ROLL = [\n",
    "    \"temp_roll_mean_4\",\"precip_roll_sum_4\",\n",
    "    \"temp_roll_mean_53\",\"precip_roll_sum_53\",\"humidity_roll_mean_53\"\n",
    "]\n",
    "\n",
    "FEATURES = BASE_FEATURES + TARGET_LAG_ROLL + ENV_LAG + ENV_ROLL\n",
    "TARGET = \"total_cases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5df398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city       MAE  n_train  n_val\n",
      "0   sj  7.265921      745    187\n",
      "1   iq  7.115772      412    104\n"
     ]
    }
   ],
   "source": [
    "train_df = make_train_df()\n",
    "city_models = {}\n",
    "val_report = []\n",
    "\n",
    "for city in [\"sj\", \"iq\"]:\n",
    "    cdf = train_df[train_df[\"city\"] == city].copy()\n",
    "\n",
    "    # Need target-lags to exist\n",
    "    needed = TARGET_LAG_ROLL + [TARGET]\n",
    "    cdf = cdf.dropna(subset=needed)\n",
    "\n",
    "    tr, va = time_split(cdf, val_frac=0.2)\n",
    "\n",
    "    Xtr = tr[FEATURES].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "    ytr = tr[TARGET].astype(float)\n",
    "\n",
    "    Xva = va[FEATURES].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "    yva = va[TARGET].astype(float)\n",
    "\n",
    "    # If any NaN remains from coercion, fill\n",
    "    Xtr = Xtr.fillna(Xtr.mean())\n",
    "    Xva = Xva.fillna(Xtr.mean())\n",
    "\n",
    "    model = get_xgb()\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    pred = model.predict(Xva)\n",
    "    mae = mean_absolute_error(yva, pred)\n",
    "\n",
    "    city_models[city] = model\n",
    "    val_report.append({\"city\": city, \"MAE\": mae, \"n_train\": len(tr), \"n_val\": len(va)})\n",
    "\n",
    "val_report_df = pd.DataFrame(val_report)\n",
    "print(val_report_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4afb9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city  year  weekofyear  total_cases\n",
      "0   sj  2008          18            7\n",
      "1   sj  2008          19            8\n",
      "2   sj  2008          20            9\n",
      "3   sj  2008          21            9\n",
      "4   sj  2008          22            7\n",
      "Saved: submission_model2_xgb_v3.csv\n"
     ]
    }
   ],
   "source": [
    "def make_submission_iterative(city_models,\n",
    "                              features_train_path=\"dengue_features_train.csv\",\n",
    "                              labels_train_path=\"dengue_labels_train.csv\",\n",
    "                              features_test_path=\"dengue_features_test.csv\",\n",
    "                              submission_path=\"submission_format.csv\",\n",
    "                              out_path=\"submission_model2_xgb_v3.csv\"):\n",
    "\n",
    "    # Prepare train history (with real total_cases)\n",
    "    Xtr_raw = pd.read_csv(features_train_path)\n",
    "    ytr = pd.read_csv(labels_train_path)\n",
    "    Xtr_raw = add_season(Xtr_raw)\n",
    "    Xtr_raw = interpolate_citywise(Xtr_raw)\n",
    "\n",
    "    train_full = Xtr_raw.merge(ytr, on=[\"city\",\"year\",\"weekofyear\"]).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "\n",
    "    # Prepare test with seeded env rolling features\n",
    "    _, Xte = make_test_df(features_train_path, features_test_path)\n",
    "    Xte = Xte.sort_values([\"city\",\"year\",\"weekofyear\"]).copy()\n",
    "\n",
    "    sub = pd.read_csv(submission_path)\n",
    "\n",
    "    preds_all = []\n",
    "\n",
    "    for city in [\"sj\", \"iq\"]:\n",
    "        model = city_models[city]\n",
    "\n",
    "        trc = train_full[train_full[\"city\"] == city].copy()\n",
    "        tec = Xte[Xte[\"city\"] == city].copy().reset_index(drop=True)\n",
    "\n",
    "        # Seed env-lag from last train row\n",
    "        last_temp = float(trc[\"reanalysis_avg_temp_k\"].iloc[-1])\n",
    "        last_prec = float(trc[\"precipitation_amt_mm\"].iloc[-1])\n",
    "\n",
    "        # History of true cases (seed for target lags)\n",
    "        history = trc[\"total_cases\"].astype(float).tolist()\n",
    "\n",
    "        yhat_list = []\n",
    "\n",
    "        for i in range(len(tec)):\n",
    "            row = tec.loc[i].copy()\n",
    "\n",
    "            # Target lags/rolling from history\n",
    "            row[\"total_cases_lag_1\"] = history[-1]\n",
    "            row[\"total_cases_lag_2\"] = history[-2]\n",
    "            row[\"total_cases_lag_3\"] = history[-3]\n",
    "            row[\"total_cases_lag_4\"] = history[-4]\n",
    "            row[\"total_cases_roll_mean_4\"] = float(np.mean(history[-4:]))\n",
    "            row[\"total_cases_roll_std_4\"]  = float(np.std(history[-4:], ddof=1)) if len(history[-4:]) >= 2 else 0.0\n",
    "\n",
    "            # Env lag 1\n",
    "            if i == 0:\n",
    "                row[\"reanalysis_avg_temp_k_lag_1\"] = last_temp\n",
    "                row[\"precipitation_amt_mm_lag_1\"]  = last_prec\n",
    "            else:\n",
    "                row[\"reanalysis_avg_temp_k_lag_1\"] = float(tec.loc[i-1, \"reanalysis_avg_temp_k\"])\n",
    "                row[\"precipitation_amt_mm_lag_1\"]  = float(tec.loc[i-1, \"precipitation_amt_mm\"])\n",
    "\n",
    "            # Build X row (force numeric)\n",
    "            Xrow = pd.DataFrame([{k: row[k] for k in FEATURES}])\n",
    "            Xrow = Xrow.apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "            Xrow = Xrow.fillna(0.0)\n",
    "\n",
    "            yhat = float(model.predict(Xrow)[0])\n",
    "            yhat = max(0.0, yhat)  # no negative cases\n",
    "\n",
    "            yhat_list.append(yhat)\n",
    "            history.append(yhat)   # recursive step\n",
    "\n",
    "        out = tec[[\"city\",\"year\",\"weekofyear\"]].copy()\n",
    "        out[\"total_cases\"] = np.round(yhat_list).astype(int)\n",
    "        preds_all.append(out)\n",
    "\n",
    "    pred_df = pd.concat(preds_all, ignore_index=True)\n",
    "\n",
    "    sub2 = sub.drop(columns=[\"total_cases\"]).merge(pred_df, on=[\"city\",\"year\",\"weekofyear\"], how=\"left\")\n",
    "    sub2[\"total_cases\"] = sub2[\"total_cases\"].fillna(0).clip(lower=0).astype(int)\n",
    "    sub2.to_csv(out_path, index=False)\n",
    "\n",
    "    return sub2\n",
    "\n",
    "sub2 = make_submission_iterative(city_models)\n",
    "print(sub2.head())\n",
    "print(\"Saved:\", \"submission_model2_xgb_v3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdf41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
