{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38161d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88822ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_raw = pd.read_csv(\"dengue_features_train.csv\")\n",
    "ytr_raw = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "Xte_raw = pd.read_csv(\"dengue_features_test.csv\")\n",
    "sub = pd.read_csv(\"submission_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c94c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [Xtr_raw, Xte_raw]:\n",
    "    df[\"sin_week\"] = np.sin(2*np.pi*df[\"weekofyear\"]/52)\n",
    "    df[\"cos_week\"] = np.cos(2*np.pi*df[\"weekofyear\"]/52)\n",
    "\n",
    "for df in [Xtr_raw, Xte_raw]:\n",
    "    df.sort_values([\"city\",\"year\",\"weekofyear\"], inplace=True)\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    for city in df[\"city\"].unique():\n",
    "        idx = df[\"city\"] == city\n",
    "        df.loc[idx, num_cols] = df.loc[idx, num_cols].interpolate(method=\"linear\", limit_direction=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617feb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = Xtr_raw.merge(ytr_raw, on=[\"city\",\"year\",\"weekofyear\"])\n",
    "train_df.sort_values([\"city\",\"year\",\"weekofyear\"], inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55f8ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [1,2,3,4]:\n",
    "    train_df[f\"total_cases_lag_{l}\"] = train_df.groupby(\"city\")[\"total_cases\"].shift(l)\n",
    "\n",
    "train_df[\"total_cases_roll_mean_4\"] = (\n",
    "    train_df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "train_df[\"total_cases_roll_std_4\"] = (\n",
    "    train_df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).std()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbde2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"reanalysis_avg_temp_k_lag_1\"] = train_df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].shift(1)\n",
    "train_df[\"precipitation_amt_mm_lag_1\"]  = train_df.groupby(\"city\")[\"precipitation_amt_mm\"].shift(1)\n",
    "\n",
    "train_df[\"temp_roll_mean_4\"] = (\n",
    "    train_df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].rolling(4, min_periods=1).mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "train_df[\"precip_roll_sum_4\"] = (\n",
    "    train_df.groupby(\"city\")[\"precipitation_amt_mm\"].rolling(4, min_periods=1).sum()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "train_df[\"temp_roll_mean_53\"] = (\n",
    "    train_df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].rolling(53, min_periods=1).mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "train_df[\"precip_roll_sum_53\"] = (\n",
    "    train_df.groupby(\"city\")[\"precipitation_amt_mm\"].rolling(53, min_periods=1).sum()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "train_df[\"humidity_roll_mean_53\"] = (\n",
    "    train_df.groupby(\"city\")[\"reanalysis_relative_humidity_percent\"].rolling(53, min_periods=1).mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1539377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = Xte_raw.copy()\n",
    "Xte.sort_values([\"city\",\"year\",\"weekofyear\"], inplace=True)\n",
    "Xte.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Xte_parts = []\n",
    "for city in [\"sj\",\"iq\"]:\n",
    "    trc = Xtr_raw[Xtr_raw[\"city\"]==city].sort_values([\"year\",\"weekofyear\"]).copy()\n",
    "    tec = Xte[Xte[\"city\"]==city].sort_values([\"year\",\"weekofyear\"]).copy().reset_index(drop=True)\n",
    "\n",
    "    seed4 = trc.tail(3)[[\"reanalysis_avg_temp_k\",\"precipitation_amt_mm\"]].copy()\n",
    "    combo4 = pd.concat([seed4, tec[[\"reanalysis_avg_temp_k\",\"precipitation_amt_mm\"]]], ignore_index=True)\n",
    "    tec[\"temp_roll_mean_4\"]  = combo4[\"reanalysis_avg_temp_k\"].rolling(4, min_periods=1).mean().iloc[len(seed4):].reset_index(drop=True)\n",
    "    tec[\"precip_roll_sum_4\"] = combo4[\"precipitation_amt_mm\"].rolling(4, min_periods=1).sum().iloc[len(seed4):].reset_index(drop=True)\n",
    "\n",
    "    seed53 = trc.tail(52)[[\"reanalysis_avg_temp_k\",\"precipitation_amt_mm\",\"reanalysis_relative_humidity_percent\"]].copy()\n",
    "    combo53 = pd.concat([seed53, tec[[\"reanalysis_avg_temp_k\",\"precipitation_amt_mm\",\"reanalysis_relative_humidity_percent\"]]], ignore_index=True)\n",
    "\n",
    "    tec[\"temp_roll_mean_53\"]  = combo53[\"reanalysis_avg_temp_k\"].rolling(53, min_periods=1).mean().iloc[len(seed53):].reset_index(drop=True)\n",
    "    tec[\"precip_roll_sum_53\"] = combo53[\"precipitation_amt_mm\"].rolling(53, min_periods=1).sum().iloc[len(seed53):].reset_index(drop=True)\n",
    "    tec[\"humidity_roll_mean_53\"] = combo53[\"reanalysis_relative_humidity_percent\"].rolling(53, min_periods=1).mean().iloc[len(seed53):].reset_index(drop=True)\n",
    "\n",
    "    Xte_parts.append(tec)\n",
    "\n",
    "Xte_feat = pd.concat(Xte_parts, ignore_index=True).sort_values([\"city\",\"year\",\"weekofyear\"]).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a42c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = [\n",
    "    \"year\",\"sin_week\",\"cos_week\",\n",
    "    \"ndvi_ne\",\"ndvi_nw\",\"ndvi_se\",\"ndvi_sw\",\n",
    "    \"precipitation_amt_mm\",\"reanalysis_precip_amt_kg_per_m2\",\n",
    "    \"reanalysis_sat_precip_amt_mm\",\"station_precip_mm\",\n",
    "    \"reanalysis_air_temp_k\",\"reanalysis_avg_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\"reanalysis_max_air_temp_k\",\n",
    "    \"station_avg_temp_c\",\"station_min_temp_c\",\"station_max_temp_c\",\n",
    "    \"reanalysis_relative_humidity_percent\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_tdtr_k\",\"station_diur_temp_rng_c\",\n",
    "]\n",
    "\n",
    "TARGET_LAG_ROLL = [\n",
    "    \"total_cases_lag_1\",\"total_cases_lag_2\",\"total_cases_lag_3\",\"total_cases_lag_4\",\n",
    "    \"total_cases_roll_mean_4\",\"total_cases_roll_std_4\",\n",
    "]\n",
    "ENV_LAG = [\"reanalysis_avg_temp_k_lag_1\",\"precipitation_amt_mm_lag_1\"]\n",
    "ENV_ROLL = [\n",
    "    \"temp_roll_mean_4\",\"precip_roll_sum_4\",\n",
    "    \"temp_roll_mean_53\",\"precip_roll_sum_53\",\"humidity_roll_mean_53\"\n",
    "]\n",
    "\n",
    "FEATURES = BASE_FEATURES + TARGET_LAG_ROLL + ENV_LAG + ENV_ROLL\n",
    "TARGET = \"total_cases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f765be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city       MAE  n_train  n_val\n",
      "0   sj  7.265921      745    187\n",
      "1   iq  7.115772      412    104\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "report = []\n",
    "\n",
    "for city in [\"sj\",\"iq\"]:\n",
    "    cdf = train_df[train_df[\"city\"]==city].copy()\n",
    "    cdf = cdf.dropna(subset=TARGET_LAG_ROLL + [TARGET]).sort_values([\"year\",\"weekofyear\"]).reset_index(drop=True)\n",
    "\n",
    "    n = len(cdf)\n",
    "    cut = int(0.8*n)\n",
    "    tr = cdf.iloc[:cut]\n",
    "    va = cdf.iloc[cut:]\n",
    "\n",
    "    Xtr = tr[FEATURES].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "    ytr = tr[TARGET].astype(float)\n",
    "\n",
    "    Xva = va[FEATURES].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "    yva = va[TARGET].astype(float)\n",
    "\n",
    "    Xtr = Xtr.fillna(Xtr.mean())\n",
    "    Xva = Xva.fillna(Xtr.mean())\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=1500, learning_rate=0.03,\n",
    "        max_depth=5, subsample=0.8, colsample_bytree=0.8,\n",
    "        min_child_weight=3, reg_lambda=1.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "    )\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    pred = model.predict(Xva)\n",
    "    mae = mean_absolute_error(yva, pred)\n",
    "\n",
    "    models[city] = model\n",
    "    report.append({\"city\": city, \"MAE\": mae, \"n_train\": len(tr), \"n_val\": len(va)})\n",
    "\n",
    "print(pd.DataFrame(report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bd80cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_parts = []\n",
    "\n",
    "train_full = Xtr_raw.merge(ytr_raw, on=[\"city\",\"year\",\"weekofyear\"]).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "\n",
    "for city in [\"sj\",\"iq\"]:\n",
    "    model = models[city]\n",
    "\n",
    "    trc = train_full[train_full[\"city\"]==city].copy()\n",
    "    tec = Xte_feat[Xte_feat[\"city\"]==city].sort_values([\"year\",\"weekofyear\"]).reset_index(drop=True).copy()\n",
    "\n",
    "    last_temp = float(trc[\"reanalysis_avg_temp_k\"].iloc[-1])\n",
    "    last_prec = float(trc[\"precipitation_amt_mm\"].iloc[-1])\n",
    "\n",
    "    history = trc[\"total_cases\"].astype(float).tolist()\n",
    "    yhat_list = []\n",
    "\n",
    "    for i in range(len(tec)):\n",
    "        row = tec.loc[i].copy()\n",
    "\n",
    "        row[\"total_cases_lag_1\"] = history[-1]\n",
    "        row[\"total_cases_lag_2\"] = history[-2]\n",
    "        row[\"total_cases_lag_3\"] = history[-3]\n",
    "        row[\"total_cases_lag_4\"] = history[-4]\n",
    "        row[\"total_cases_roll_mean_4\"] = float(np.mean(history[-4:]))\n",
    "        row[\"total_cases_roll_std_4\"]  = float(np.std(history[-4:], ddof=1)) if len(history[-4:]) >= 2 else 0.0\n",
    "\n",
    "        if i == 0:\n",
    "            row[\"reanalysis_avg_temp_k_lag_1\"] = last_temp\n",
    "            row[\"precipitation_amt_mm_lag_1\"]  = last_prec\n",
    "        else:\n",
    "            row[\"reanalysis_avg_temp_k_lag_1\"] = float(tec.loc[i-1, \"reanalysis_avg_temp_k\"])\n",
    "            row[\"precipitation_amt_mm_lag_1\"]  = float(tec.loc[i-1, \"precipitation_amt_mm\"])\n",
    "\n",
    "        Xrow = pd.DataFrame([{k: row[k] for k in FEATURES}])\n",
    "        Xrow = Xrow.apply(pd.to_numeric, errors=\"coerce\").astype(float).fillna(0.0)\n",
    "\n",
    "        yhat = float(model.predict(Xrow)[0])\n",
    "        yhat = max(0.0, yhat)\n",
    "\n",
    "        yhat_list.append(yhat)\n",
    "        history.append(yhat)\n",
    "\n",
    "    out = tec[[\"city\",\"year\",\"weekofyear\"]].copy()\n",
    "    out[\"total_cases\"] = np.round(yhat_list).astype(int)\n",
    "    pred_parts.append(out)\n",
    "\n",
    "pred_df = pd.concat(pred_parts, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a24fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  city  year  weekofyear  total_cases\n",
      "0   sj  2008          18            7\n",
      "1   sj  2008          19            8\n",
      "2   sj  2008          20            9\n",
      "3   sj  2008          21            9\n",
      "4   sj  2008          22            7\n",
      "Saved: submission_model2_xgb_v3.csv\n"
     ]
    }
   ],
   "source": [
    "sub2 = sub.drop(columns=[\"total_cases\"]).merge(pred_df, on=[\"city\",\"year\",\"weekofyear\"], how=\"left\")\n",
    "sub2[\"total_cases\"] = sub2[\"total_cases\"].fillna(0).clip(lower=0).astype(int)\n",
    "sub2.to_csv(\"submission_model2_xgb_v3.csv\", index=False)\n",
    "\n",
    "print(sub2.head())\n",
    "print(\"Saved: submission_model2_xgb_v3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
