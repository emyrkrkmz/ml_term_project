{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32265cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_csv(\"dengue_features_train.csv\")\n",
    "y = pd.read_csv(\"dengue_labels_train.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7f42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def force_numeric(df, cols):\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "    \n",
    "def add_season(df):\n",
    "    df = df.copy()\n",
    "    df[\"sin_week\"] = np.sin(2*np.pi*df[\"weekofyear\"]/52)\n",
    "    df[\"cos_week\"] = np.cos(2*np.pi*df[\"weekofyear\"]/52)\n",
    "    return df\n",
    "\n",
    "def make_train_features(features_train_path=\"dengue_features_train.csv\",\n",
    "                        labels_train_path=\"dengue_labels_train.csv\"):\n",
    "    X = pd.read_csv(features_train_path)\n",
    "    y = pd.read_csv(labels_train_path)\n",
    "\n",
    "    df = X.merge(y, on=[\"city\",\"year\",\"weekofyear\"]).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "    df = add_season(df)\n",
    "\n",
    "    # Target lag: strictly past\n",
    "    for l in [1,2,3,4]:\n",
    "        df[f\"total_cases_lag_{l}\"] = df.groupby(\"city\")[\"total_cases\"].shift(l)\n",
    "\n",
    "    # Rolling: geçmiş 4 hafta (current week dahil değil!)\n",
    "    # shift(1) -> current week target'ı asla feature'a girmez\n",
    "    df[\"total_cases_roll_mean_4\"] = (\n",
    "        df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).mean().reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"total_cases_roll_std_4\"] = (\n",
    "        df.groupby(\"city\")[\"total_cases\"].shift(1).rolling(4).std().reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Environment lag (sadece 1)\n",
    "    df[\"reanalysis_avg_temp_k_lag_1\"] = df.groupby(\"city\")[\"reanalysis_avg_temp_k\"].shift(1)\n",
    "    df[\"precipitation_amt_mm_lag_1\"]  = df.groupby(\"city\")[\"precipitation_amt_mm\"].shift(1)\n",
    "\n",
    "    # İlk haftalarda lag/rolling NaN olacak -> train/val'da drop edeceğiz\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14910e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = [\n",
    "    \"year\", \"sin_week\", \"cos_week\",\n",
    "    \"ndvi_ne\",\"ndvi_nw\",\"ndvi_se\",\"ndvi_sw\",\n",
    "    \"precipitation_amt_mm\",\"reanalysis_precip_amt_kg_per_m2\",\n",
    "    \"reanalysis_sat_precip_amt_mm\",\"station_precip_mm\",\n",
    "    \"reanalysis_air_temp_k\",\"reanalysis_avg_temp_k\",\n",
    "    \"reanalysis_min_air_temp_k\",\"reanalysis_max_air_temp_k\",\n",
    "    \"station_avg_temp_c\",\"station_min_temp_c\",\"station_max_temp_c\",\n",
    "    \"reanalysis_relative_humidity_percent\",\n",
    "    \"reanalysis_specific_humidity_g_per_kg\",\n",
    "    \"reanalysis_dew_point_temp_k\",\n",
    "    \"reanalysis_tdtr_k\",\"station_diur_temp_rng_c\",\n",
    "]\n",
    "\n",
    "LAG_FEATURES = [\n",
    "    \"total_cases_lag_1\",\"total_cases_lag_2\",\"total_cases_lag_3\",\"total_cases_lag_4\",\n",
    "    \"total_cases_roll_mean_4\",\"total_cases_roll_std_4\",\n",
    "    \"reanalysis_avg_temp_k_lag_1\",\"precipitation_amt_mm_lag_1\",\n",
    "]\n",
    "\n",
    "FEATURES_V2 = BASE_FEATURES + LAG_FEATURES\n",
    "TARGET = \"total_cases\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92815843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>7.458559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iq</td>\n",
       "      <td>4.718907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city       MAE\n",
       "0   sj  7.458559\n",
       "1   iq  4.718907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def time_split(city_df, val_frac=0.2):\n",
    "    city_df = city_df.sort_values([\"year\",\"weekofyear\"])\n",
    "    n = len(city_df)\n",
    "    cut = int((1 - val_frac) * n)\n",
    "    return city_df.iloc[:cut], city_df.iloc[cut:]\n",
    "\n",
    "def get_model():\n",
    "    try:\n",
    "        from xgboost import XGBRegressor\n",
    "        return XGBRegressor(\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            objective=\"reg:squarederror\",\n",
    "        )\n",
    "    except Exception:\n",
    "        # Fallback: sklearn (genelde daha zayıf ama çalışır)\n",
    "        from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "        return HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "df = make_train_features()\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "\n",
    "for city in [\"sj\",\"iq\"]:\n",
    "    cdf = df[df[\"city\"] == city].copy()\n",
    "\n",
    "    # lag/rolling NaN satırlarını at\n",
    "    cdf = cdf.dropna(subset=LAG_FEATURES + [TARGET])\n",
    "\n",
    "    tr, va = time_split(cdf, val_frac=0.2)\n",
    "    Xtr, ytr = tr[FEATURES_V2], tr[TARGET]\n",
    "    Xva, yva = va[FEATURES_V2], va[TARGET]\n",
    "\n",
    "    model = get_model()\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    pred = model.predict(Xva)\n",
    "    mae = mean_absolute_error(yva, pred)\n",
    "\n",
    "    results.append({\"city\": city, \"MAE\": mae})\n",
    "    models[city] = model\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5927198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    30\n",
      "int64       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[FEATURES_V2].dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ef3580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  total_cases\n",
       "0   sj  2008          18            6\n",
       "1   sj  2008          19            7\n",
       "2   sj  2008          20           10\n",
       "3   sj  2008          21            8\n",
       "4   sj  2008          22            8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_test_predictions_iterative(models,\n",
    "                                    features_test_path=\"dengue_features_test.csv\",\n",
    "                                    features_train_path=\"dengue_features_train.csv\",\n",
    "                                    labels_train_path=\"dengue_labels_train.csv\",\n",
    "                                    submission_path=\"submission_format.csv\"):\n",
    "    Xtr = pd.read_csv(features_train_path)\n",
    "    ytr = pd.read_csv(labels_train_path)\n",
    "    Xte = pd.read_csv(features_test_path)\n",
    "    sub = pd.read_csv(submission_path)\n",
    "\n",
    "    Xtr = add_season(Xtr)\n",
    "    Xte = add_season(Xte)\n",
    "\n",
    "    train_full = Xtr.merge(ytr, on=[\"city\",\"year\",\"weekofyear\"]).sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "    test_full  = Xte.sort_values([\"city\",\"year\",\"weekofyear\"])\n",
    "\n",
    "    preds_all = []\n",
    "\n",
    "    for city in [\"sj\",\"iq\"]:\n",
    "        model = models[city]\n",
    "\n",
    "        trc = train_full[train_full[\"city\"] == city].copy()\n",
    "        tec = test_full[test_full[\"city\"] == city].copy()\n",
    "\n",
    "        # geçmiş total_cases listesi: train gerçekleriyle seed\n",
    "        history = trc[\"total_cases\"].tolist()\n",
    "\n",
    "        # test satırlarını sırayla gez\n",
    "        preds_city = []\n",
    "        for _, row in tec.iterrows():\n",
    "            # lag feature'ları history'den üret\n",
    "            lag1 = history[-1]\n",
    "            lag2 = history[-2]\n",
    "            lag3 = history[-3]\n",
    "            lag4 = history[-4]\n",
    "\n",
    "            roll_mean_4 = np.mean(history[-4:])\n",
    "            roll_std_4  = np.std(history[-4:], ddof=1) if len(history[-4:]) >= 2 else 0.0\n",
    "\n",
    "            # env lag_1: environment için 1 hafta geriden almak için\n",
    "            # pratikte: tec'te bir önceki satırın value'su; ilk satırda train'in son value'su\n",
    "            # Bunun için birlikte dizi kuruyoruz:\n",
    "            # (train son env değeri) + (test env değerleri)\n",
    "            # ve index'i kaydırıyoruz\n",
    "            # Kolay yol:\n",
    "            # geçmiş env değerleri için train son + test'e kadar kümülatif ilerle\n",
    "            # burada tec üzerinde i kullanmak daha kolay:\n",
    "            # (aşağıda i ile yapacağız)\n",
    "            preds_city.append(row)  # placeholder\n",
    "\n",
    "        # env lag'leri için index ile tekrar döngü (daha temiz)\n",
    "        tec = tec.reset_index(drop=True)\n",
    "        last_temp = trc[\"reanalysis_avg_temp_k\"].iloc[-1]\n",
    "        last_prec = trc[\"precipitation_amt_mm\"].iloc[-1]\n",
    "\n",
    "        history = trc[\"total_cases\"].tolist()\n",
    "        yhat_list = []\n",
    "\n",
    "        for i in range(len(tec)):\n",
    "            row = tec.loc[i].copy()\n",
    "\n",
    "            row[\"total_cases_lag_1\"] = history[-1]\n",
    "            row[\"total_cases_lag_2\"] = history[-2]\n",
    "            row[\"total_cases_lag_3\"] = history[-3]\n",
    "            row[\"total_cases_lag_4\"] = history[-4]\n",
    "            row[\"total_cases_roll_mean_4\"] = np.mean(history[-4:])\n",
    "            row[\"total_cases_roll_std_4\"]  = np.std(history[-4:], ddof=1) if len(history[-4:]) >= 2 else 0.0\n",
    "\n",
    "            # env lag 1\n",
    "            if i == 0:\n",
    "                row[\"reanalysis_avg_temp_k_lag_1\"] = last_temp\n",
    "                row[\"precipitation_amt_mm_lag_1\"]  = last_prec\n",
    "            else:\n",
    "                row[\"reanalysis_avg_temp_k_lag_1\"] = tec.loc[i-1, \"reanalysis_avg_temp_k\"]\n",
    "                row[\"precipitation_amt_mm_lag_1\"]  = tec.loc[i-1, \"precipitation_amt_mm\"]\n",
    "\n",
    "            Xrow = row[FEATURES_V2].to_frame().T\n",
    "            Xrow = Xrow.apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "            Xrow = Xrow.fillna(0.0)\n",
    "\n",
    "            yhat = float(model.predict(Xrow)[0])\n",
    "\n",
    "            # Dengue negatif olmaz\n",
    "            yhat = max(0.0, yhat)\n",
    "\n",
    "            yhat_list.append(yhat)\n",
    "            history.append(yhat)  # kritik: bir sonraki haftanın lag'i bu olacak\n",
    "\n",
    "        out = tec[[\"city\",\"year\",\"weekofyear\"]].copy()\n",
    "        out[\"total_cases\"] = np.round(yhat_list).astype(int)\n",
    "        preds_all.append(out)\n",
    "\n",
    "    pred_df = pd.concat(preds_all, ignore_index=True)\n",
    "\n",
    "    sub2 = sub.drop(columns=[\"total_cases\"]).merge(pred_df, on=[\"city\",\"year\",\"weekofyear\"], how=\"left\")\n",
    "    sub2[\"total_cases\"] = sub2[\"total_cases\"].fillna(0).clip(lower=0).astype(int)\n",
    "    sub2.to_csv(\"submission_model2_xgb_v1.csv\", index=False)\n",
    "\n",
    "    return sub2\n",
    "\n",
    "# kullanım:\n",
    "sub2 = make_test_predictions_iterative(models)\n",
    "sub2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6214719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2010.766827</td>\n",
       "      <td>26.439904</td>\n",
       "      <td>9.399038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.434835</td>\n",
       "      <td>14.978257</td>\n",
       "      <td>7.632486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  weekofyear  total_cases\n",
       "count   416.000000  416.000000   416.000000\n",
       "mean   2010.766827   26.439904     9.399038\n",
       "std       1.434835   14.978257     7.632486\n",
       "min    2008.000000    1.000000     0.000000\n",
       "25%    2010.000000   13.750000     5.000000\n",
       "50%    2011.000000   26.000000     7.000000\n",
       "75%    2012.000000   39.000000    10.000000\n",
       "max    2013.000000   53.000000    46.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b15458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
